{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = image_dataset_from_directory(\n",
    "    directory = './train',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary',\n",
    "    batch_size = 64,\n",
    "    image_size = (224,224)\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    directory = './test',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'binary',\n",
    "    batch_size = 64,\n",
    "    image_size = (224,224)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize images to [0,1]\n",
    "def norm_img(image, label):\n",
    "    return image/255, label\n",
    "\n",
    "train_dataset = train_dataset.map(norm_img)\n",
    "test_dataset = test_dataset.map(norm_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "new_model = Model(inputs = base_model.input, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer=Adam(learning_rate=0.001), metrics= ['accuracy'], loss= 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742449735.763238   18794 service.cc:148] XLA service 0x7f3efc00caf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742449735.765447   18794 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 6GB Laptop GPU, Compute Capability 8.6\n",
      "2025-03-20 11:18:55.854473: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1742449736.439521   18794 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-20 11:18:59.246412: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-20 11:18:59.246564: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-20 11:18:59.813723: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-20 11:19:00.014449: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-20 11:19:00.014691: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-20 11:19:01.035086: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1742449757.631882   18794 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 348ms/step - accuracy: 0.8292 - loss: 0.5125 - val_accuracy: 0.9068 - val_loss: 0.2096\n",
      "Epoch 2/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 300ms/step - accuracy: 0.9414 - loss: 0.1424 - val_accuracy: 0.9368 - val_loss: 0.1556\n",
      "Epoch 3/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 303ms/step - accuracy: 0.9582 - loss: 0.1059 - val_accuracy: 0.9268 - val_loss: 0.1877\n",
      "Epoch 4/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 297ms/step - accuracy: 0.9684 - loss: 0.0833 - val_accuracy: 0.9352 - val_loss: 0.1773\n",
      "Epoch 5/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 301ms/step - accuracy: 0.9786 - loss: 0.0572 - val_accuracy: 0.9134 - val_loss: 0.2566\n"
     ]
    }
   ],
   "source": [
    "history = new_model.fit(train_dataset, validation_data= test_dataset, epochs= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 228ms/step - accuracy: 0.9119 - loss: 0.2609\n",
      "Validation Accuracy: 91.34%\n"
     ]
    }
   ],
   "source": [
    "_ , accuracy = new_model.evaluate(test_dataset)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_resnet = ResNet50(include_top=False, weights= 'imagenet', input_shape=(224,224,3))\n",
    "\n",
    "for layer in base_model_resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model_resnet.output\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = Dense(1, activation= 'sigmoid')(x)\n",
    "\n",
    "new_model2 = Model(inputs = base_model_resnet.input, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model2.compile(optimizer=Adam(learning_rate = 0.001), metrics = ['accuracy'], loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 234ms/step - accuracy: 0.5685 - loss: 1.5796 - val_accuracy: 0.6522 - val_loss: 0.6166\n",
      "Epoch 2/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 201ms/step - accuracy: 0.6690 - loss: 0.6070 - val_accuracy: 0.6768 - val_loss: 0.5994\n",
      "Epoch 3/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 199ms/step - accuracy: 0.6953 - loss: 0.5784 - val_accuracy: 0.7202 - val_loss: 0.5533\n",
      "Epoch 4/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 193ms/step - accuracy: 0.6954 - loss: 0.5776 - val_accuracy: 0.6772 - val_loss: 0.5940\n",
      "Epoch 5/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 188ms/step - accuracy: 0.7145 - loss: 0.5533 - val_accuracy: 0.7366 - val_loss: 0.5349\n"
     ]
    }
   ],
   "source": [
    "history = new_model2.fit(train_dataset, epochs = 5, validation_data= test_dataset )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 152ms/step - accuracy: 0.7382 - loss: 0.5309\n",
      "Validation Accuracy: 73.66%\n"
     ]
    }
   ],
   "source": [
    "_ , accuracy = new_model2.evaluate(test_dataset)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
